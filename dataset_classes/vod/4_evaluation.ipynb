{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation Example\n",
    "\n",
    "This example provides an insight on how to evaluate a model on the dataset. The same evaluation procedure is the basis of the upcoming leaderboard.\n",
    "For the evaluation the 'vod.evaluation' module is used. The evaluation module provides a number of metrics that can be used to evaluate a model. The metrics are:\n",
    "- Per class AP for the entire annotated area\n",
    "- Per class AP for the driving corridor\n",
    "- Per clas AOS for the entire annotated area\n",
    "- Per class AOS for the driving corridor\n",
    "\n",
    "The evaluation procedure can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating kitti by default\n",
      "mAP Image BBox finished\n",
      "mAP bev BBox finished\n",
      "mAP 3D BBox finished\n",
      "Evaluating kitti by ROI\n",
      "mAP Image BBox finished\n",
      "mAP bev BBox finished\n",
      "mAP 3D BBox finished\n",
      "Results: \n",
      "Entire annotated area: \n",
      "Car: 25.525719831769656 \n",
      "Pedestrian: 25.061868496971517 \n",
      "Cyclist: 40.682414698162724 \n",
      "mAP: 30.423334342301303 \n",
      "Driving corridor area: \n",
      "Car: 89.62930867728619 \n",
      "Pedestrian: 68.55636970921907 \n",
      "Cyclist: 83.24705620654387 \n",
      "mAP: 80.47757819768304 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vod.evaluation import Evaluation\n",
    "import os\n",
    "\n",
    "# When the instance is created, the label locations are required.\n",
    "evaluation = Evaluation(test_annotation_file=os.path.join('example_set', 'label'))\n",
    "\n",
    "# Using the evaluate method, the model can be evaluated on the detection labels.\n",
    "results = evaluation.evaluate(\n",
    "    result_path=os.path.join('example_set', 'detection'),\n",
    "    current_class=[0, 1, 2])\n",
    "\n",
    "print(\"Results: \\n\"\n",
    "      f\"Entire annotated area: \\n\"\n",
    "      f\"Car: {results['entire_area']['Car_3d_all']} \\n\"\n",
    "      f\"Pedestrian: {results['entire_area']['Pedestrian_3d_all']} \\n\"\n",
    "      f\"Cyclist: {results['entire_area']['Cyclist_3d_all']} \\n\"\n",
    "      f\"mAP: {(results['entire_area']['Car_3d_all'] + results['entire_area']['Pedestrian_3d_all'] + results['entire_area']['Cyclist_3d_all']) / 3} \\n\"\n",
    "      f\"Driving corridor area: \\n\"\n",
    "      f\"Car: {results['roi']['Car_3d_all']} \\n\"\n",
    "      f\"Pedestrian: {results['roi']['Pedestrian_3d_all']} \\n\"\n",
    "      f\"Cyclist: {results['roi']['Cyclist_3d_all']} \\n\"\n",
    "      f\"mAP: {(results['roi']['Car_3d_all'] + results['roi']['Pedestrian_3d_all'] + results['roi']['Cyclist_3d_all']) / 3} \\n\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}